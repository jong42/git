\chapter{Optimierungsverfahren für allgemeine Probleme}

Allgemeine, unrestringierte Probleme mit \textbf nichtlinearer, differenzierbarer Zielfunktion vom Typ
$
			\begin{aligned}
				\min_{x\in\R^n}
				& & & f(x) & & &
			\end{aligned} $ lassen sich mit den im vorigen Kapitel behandelten Verfahren nicht lösen. Der negative Gradient als Richtung des steilsten Abstiegs ist immer noch als Abstiegsrichtung geeignet, allerdings kann keine exakte Schrittweite mehr bestimmt werden.\\
Sei $x^{(k)}$ ein Iterationspunkt mit einer Abstiegsrichtung $d^{(k)}$. Bei hinreichend kleiner Schrittweite $\sigma_k$ gilt:
\begin{equation}
	f(x^{(k+1)}) = f(x^{(k)} + \sigma_kd^{(k)}) < f(x^{(k)})
\end{equation}
Die Folge ${f(x^{(k)})}$ ist streng monoton fallend. Das muss jedoch nicht bedeuten, dass das Problem konvergiert.
\paragraph{Beispiel für nicht konvergierende Probleme}

$f(x)= x^2$, $x^{(0)} = 1$

\input{tikz/parabel}
$d^{(0)} = -1$ \\
Abstiegsrichtung: $\nabla f(x^{(k)})^T d^{(k)}$\\
\noindent\hspace*{32mm}%
 $=  -2x^{(k)} < 0 \, \, \, \, \forall x^{(k)} > 0$\\
Betrachte Schrittweite $\sigma_k = 1/2^{k+2} \, \, \, \, \forall k \geq 0$


$x^{(k-1)} = x^k + \sigma_k d^{(k)}$ \\
$= x^{(k)} - \sigma_k$ \\
$= x^{(k)} - (1/2)^{(k+2)}$ \\
$= x^{(0)} - \sum\limits_{i=1}^k (1/2)^{(i+2)}$ \\
$= 1 - \sum\limits_{i=1}^k (1/2)^{(i+2)}$ \\
$= 1/2 + (1/2)^{(k+2)}  \underbrace{\Rightarrow}_{k\Rightarrow \infty} 1/2$


Die Folge $x^{(k)}$ konvergiert nicht gegen $x^{*} = 0$.


\paragraph{Mögliche Schrittweitenstrategien}

\begin{itemize}
	\item Konstante Schrittweite $\sigma_k = \sigma > 0$
	\item Kleiner werdende Schrittweiten, z.B. $\sigma_k = 1/k$
	\item Exakte Schrittweiten, z.B. $\sigma_k = arg \min {\sigma \geq 0} f(x^{(k)} + \sigma d^{(k)})$
	\item  Armijo-Verfahren
\end{itemize}

\section{Das Schrittweitenverfahren von Armijo}

Seien x und eine Abstiegsrichtung d von f in x gegeben. Weiter sei
$c_1 \in ]0, 1[$ eine von x und d unabhängige Konstante. Zur Berechnung
einer effizienten Schrittweite $\sigma$ soll die Abstiegsbedingung
$f(x + \sigma d) \leq f(x) + c_1 \sigma \nabla f(x)^Td$
erfüllt werden. Damit die Schrittweite nicht zu klein wird, fordert man
zusätzlich mit einer von x und d unabhängigen Konstante $c_2 > 0$, dass

\begin{equation}
\sigma \geq -c_2 (\nabla f(x)^Td) / ||d||^2 
\end{equation}

Abbildung einfügen


Gegeben seien von x und d unabhängige Konstanten:
$\delta \in ]0, 1[$, $\gamma > 0$ und $0 < \beta_1 \leq \beta_2 < 1$

\begin{enumerate}
	\item  Wähle eine Startschrittweite $\sigma_0$, für die mit $c_2 = \gamma$ gilt:
	\begin{equation}
	\sigma \geq - \gamma (\nabla f(x)^Td)/||d||^2
	\end{equation}
	Setze $j = 0$.
	\item Ist die Abstiegsbedingung
	 $f(x + \sigma d) \leq f(x) + \delta \sigma_j \nabla f(x)^Td$
	 erfüllt, dann setze $\sigma_A = \sigma_j$ und stoppe das Verfahren.
	\item Wähle $\sigma_j+ 1 \in [\beta_1 \sigma_j , \beta_2 \sigma_j ]$.
	\item Setze $j = j + 1$ und gehe zu 2.
\end{enumerate}


Praktisch haben sich folgende Werte bewährt:
\begin{itemize}
\item $\delta$ sollte klein sein; Größenordnung: $\delta = 0.01$
\item$\gamma$ sollte so gewählt werden, dass die Schrittweite 1 und die exakte
Schrittweite nicht ausgeschlossen werden. $\gamma = 10^{-4}$
\item $\sigma_0 = 1$ oder als Approximation der exakten Schrittweite:
\begin{equation}
\sigma_0 = - (\nabla f(x)^T d) / (2 (f(x + d) - f(x) - \nabla f(x)^T d))
\end{equation}
\item Zur Berechnung von $\sigma_j,j \geq 1$ kann man $\beta_1 = \beta_2 = \beta$ wählen:
\begin{equation}
\sigma_j = \beta^j \sigma_0 
\end{equation}
$j = 1, 2, . . .$

\end{itemize}
Oft wählt man $\beta = 1/2$

\subsection{Konvergenz des Verfahrens}

Die theoretische Version des Armijo-Verfahrens konvergiert nach endlich
vielen Schritten, falls die Standard-Voraussetzung erfüllt ist und die
Ableitung der Zielfunktion Lipschitz-stetig ist, d. h., es gibt ein $L > 0$ mit
\begin{equation}
|| \nabla f(x) - \nabla f(y)|| \leq L ||x - y|| \forall x,y \in N_0
\end{equation}

Bei einer praktischen Implementierung mit der diskutierten
Parameterwahl ist jedoch endliche Konvergenz nicht sichergestellt.
Daher sollte eine maximale Iterationszahl vorgegeben werden. Sollte
keine Konvergenz eintreten, kann das Verfahren mit anderen Parametern
neugestartet werden.

\paragraph{Beispiel zur Lipschitz-Stetigkeit}

$f(x_1,x_2) = (x_1)^2 + (x_2)^2 $
$\nabla f(x_1,x_2) = \begin{bmatrix}2x_1\\2x_2\end{bmatrix}$

$\nabla f(x_1,x_2)$ ist $\infty$ mal stetig differenzierbar

\begin{equation}
|| \nabla f(x) - \nabla f(y) || = || 2 \begin{bmatrix}x_1\\x_2\end{bmatrix} -2 \begin{bmatrix}y_1\\y_2\end{bmatrix} ||\\
= ||2 \begin{bmatrix}x_1 -y_1\\x_2 - y_2\end{bmatrix} ||\\
\leq 2 ||x-y||
\end{equation}

$\nabla f$ ist lipschitz-stetig mit L=2

Die Lipschitz-Stetigkeit kann als ein Verhältnis zwischen Funktionswerten und Argumenten interpretiert werden.

\section{Das Gradientenverfahren}

Suchrichtung: $d^{(k)} = -\nabla f(x^{(k)})$
\begin{itemize}
	\item Wähle einen Startpunkt $x^{(0)} \in R^n$ und setze k = 0.
	\item Ist $\nabla f(x^{(k)}) = 0_n$ , dann stoppe das Verfahren.
	\item Berechne eine effiziente Schrittweite $\sigma_k$ (bspw. Armijo) und setze
	$x^{(k+1)} = x{(k)} - \sigma_k \nabla f(x^{(k)})$ .
	\item Setze $k = k + 1$ und gehe zu 2.
\end{itemize}

Der negative Gradient ist die eindeutig bestimmte Lösung des quadratischen Problems
\begin{equation}
	\min_{d\in\R^n} \underbrace{f(x^{(k)}) + \nabla f(x^{(k)})^Td}_{Taylor-Approximation 1. Ordnung} + \underbrace{1/2 d^Td}_{\underbrace{1/(2\sigma)||x^{(k+1)} - x^{(k)}||^2}_{Abstand x^{(k+1)} zu x^{(k)}}}
\end{equation}
	
$x^{(k+1)} = x^{(k)} + \sigma d$
	
$d = (x^{(k+1)}-x^{(k)})/\sigma$
	
für: $Q=I_n$
$q = \nabla f(x^{(k)})$
$Qd + q = 0$
$Id + \nabla f(x^{(k)}) = 0$   <=> $d=-\nabla f(x^{(k)})$

\subsection{Funktionenklassen}	

$\mathcal{F}_L^{k,l} (R^n)$

Menge aller konvexen Funktionen	$\mathcal{F}:R^n \Rightarrow R$, die k mal stetig differenzierbar sind und deren l-te ABleitung lipschitz-stetig mit Konstante L ist, d.h.

\begin{equation}
||f^{(l)} (x) - f^{(l)} (y)|| \leq L ||x-y|| \forall x,y \in R^n
\end{equation}

\begin{itemize}
	\item Offensichtlich ist $k \geq l$
	\item $\mathcal{F}_L^{k_1,l} \leq \mathcal{F}_L^{k_2,l}, k_1 \geq k_2$
	\item $f_1 \in \mathcal{F}_{L_1}^{k,l}, f_2 \in \mathcal{F}_{L_2}^{k,l}, \alpha, \beta \geq 0$
\end{itemize}

$\Rightarrow \alpha f_1 + \beta f_2 \in \mathcal{F}_{\alpha L_1 + \beta L_2}^{k,l}$


$\mathcal{F}^k \Rightarrow$ Menge aller konvexen Funktionen, die k mal stetig differenzierbar sind.

Für Gradientenverfahren relevant:   $\mathcal{F}^{1,1}_L$
Eigenschaft von $\mathcal{F}^1$: Für $f \in \mathcal{F}^1$ gilt:\\

\begin{equation}
	f(y) \geq f(x+ \nabla f(x)^T (y-x)
\end{equation}

Eigenschaften von $\mathcal{F}^{1,1}_L$: Für $f \in \mathcal{F}^{1,1}_L$ gilt:\\
\begin{itemize}
	\item $f(y) \leq f(x) + \nabla f(x)^T (y-x) + L/2 ||x-y||^2$
	\item $f(x) + \nabla f(x)^T (y-x) + 1/(2L) || \nabla f(x) - \nabla f(y)||^2 \leq f(y)$
	\item $ 1/L || \nabla f(x) - \nabla f(y)||^2 \leq (\nabla f(x) - \nabla f(y))^T (x-y)$
	\item $(\nabla f(x) - \nabla f(y))^T (x-y) \leq L ||x-y||^2$
	\item $ \alpha f(x) + (1-\alpha) f(y) \geq f(\alpha x + (1-\alpha)y) + (\alpha(1-\alpha))/(2L) || \nabla f(x) - \nabla f(y)||^2$
	\item $\alpha f(x) + (1-\alpha) f(y) \geq f(\alpha x + (1-\alpha)y) + \alpha (1-\alpha) L/2 ||x-y||^2$
\end{itemize}

\begin{Definition}
Eine stetig differenzierbare Funktion f heißt gleichmäßig konvex mit Konvexitätsparameter $\mu > 0 (f \in S_\mu^1)$, wenn $f(y) \geq \nabla f(x)^T (y-x) + (1/2) \mu ||y-x||^2 $
\end{Definition}

Wir definieren den Raum $S_{\mu,L}^{k,l}$ analog zu$ \mathcal{F}_L^{k,l} $

Eigenschaften:
$f_1 \in S_{\mu_1}^1, f_2 \in S_{\mu_2}^1, \alpha, \beta \geq 0 $

$\Rightarrow  \alpha f_1 + \beta f_2 \in S^{1}_{\alpha mu_1 + \beta mu_2}$


\begin{Lemma}
	Eine zweimal stetig differenzierbare Funktion f gehört zu $S^{2}_{\mu}$
\end{Lemma}

$\Leftrightarrow f^n(x) \geq \mu*I_n  \forall x \in R^n$

Für $f \in S_{\mu,L}^{2,1}$ gilt:\\
$\mu I_n \leq f''(x) \leq L I_n$

\begin{Definition}
$Q = L/\mu$ ist die Kondition der Funktion f.
\end{Definition}

Bei kleinen Q führen kleine Änderungen im Problem zu kleinen Änderungen im Funktionswert.
	
\subsection{Konvergenz des Gradientenverfahrens}	

Der Einfachheit halber betrachten wir nur die konstante
Schrittweitenstrategie $\sigma_k = \sigma$.

\paragraph{Theorem}
Sei $f : R^n \Rightarrow R$ konvex und stetig differenzierbar und die Ableitung $\nabla f$
Lipschitz-stetig mit Lipschitzkonstante $L > 0$. Dann gilt für das
Gradientenverfahren mit konstanter Schrittweite $0 < \sigma \leq 1/L$

\begin{equation}
f(x^{(k)}) - f(x^{*}) \leq (||x^{(0)} - x^{*}||^2)/2\sigma k
\end{equation}

aufgehört bei 08-15








